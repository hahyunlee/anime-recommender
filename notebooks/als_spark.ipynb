{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import findspark\n",
    "# Find Spark Locally\n",
    "location = findspark.find()\n",
    "findspark.init(location, edit_rc=True)\n",
    "\n",
    "import pyspark as ps    # for the pyspark suite\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType, DateType, TimestampType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"anime recommender\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "import gc\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, lower\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_filename = '../data/anime.csv'\n",
    "ratings_filename = '../data/rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anime_raw = sc.textFile(anime_filename)\n",
    "# ratings_raw = sc.textFile(ratings_filename)\n",
    "anime_raw = spark.read.load(anime_filename,format='csv',header=True,inferSchema=True)\n",
    "ratings_raw = spark.read.load(ratings_filename,format='csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df = anime_raw.select(['anime_id','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_raw.select(['user_id','anime_id','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ALS model\n",
    "model = ALS(\n",
    "    userCol = 'user_id',\n",
    "    itemCol = 'anime_id',\n",
    "    ratingCol = 'rating',\n",
    "    coldStartStrategy = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train,val,test = ratings_df.randomSplit((0.6,0.2,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning ALS model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = float('inf')\n",
    "best_rank=-1\n",
    "best_regularization=0\n",
    "best_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIter = 10\n",
    "rank = 1\n",
    "reg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = model.setMaxIter(maxIter).setRank(rank).setRegParam(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse',\n",
    "                                        labelCol='rating',\n",
    "                                        predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                        labelCol=\"rating\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Methods / ALS Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ALS(model,training_data, validation_data, maxIter, regParams, ranks):\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = model.setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(maxIter,regParams,ranks,split_ratio=(0.6,0.2,0.2)):\n",
    "    train, val, test = ratings_df.randomSplit(split_ratio)\n",
    "    # tune model to get best model for predictions\n",
    "    model = tune_ALS(model, train, val, maxIter, regParams, ranks)\n",
    "    \n",
    "    # test model\n",
    "    predictions = self.model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print('The out-of-sample RMSE of the best tuned model is:', rmse)\n",
    "    # clean up\n",
    "    del train, val, test, predictions, evaluator\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex matching closest name to animes\n",
    "def regex_matching(fav_anime):\n",
    "    print('You have input anime:', fav_anime)\n",
    "    matches_df = anime_df \\\n",
    "        .filter(\n",
    "            lower(\n",
    "                col('name')\n",
    "            ).like('%{}%'.format(fav_anime.lower()))\n",
    "        ) \\\n",
    "        .select('anime_id', 'name')\n",
    "    if not len(matches_df.take(1)):\n",
    "        print('Oops! No match is found')\n",
    "    else:\n",
    "        anime_ids = matches_df.rdd.map(lambda r: r[0]).collect()\n",
    "        names = matches_df.rdd.map(lambda r: r[1]).collect()\n",
    "        print('Found possible matches in our database: '\n",
    "              '{0}\\n'.format([x for x in names]))\n",
    "        return anime_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a user's anime ratings to ratings_df\n",
    "def append_ratings(user_id,anime_ids):\n",
    "     # create new user rdd\n",
    "    user_rdd = self.sc.parallelize(\n",
    "        [(user_id, anime_id, 5.0) for anime_id in anime_ids])\n",
    "    # transform to user rows\n",
    "    user_rows = user_rdd.map(\n",
    "        lambda x: Row(\n",
    "            user_id=int(x[0]),\n",
    "            anime_id=int(x[1]),\n",
    "            rating=float(x[2])\n",
    "        )\n",
    "    )\n",
    "    # transform rows to spark DF\n",
    "    user_df = spark.createDataFrame(user_rows) \\\n",
    "        .select(ratings_df.columns)\n",
    "    # append to ratingsDF\n",
    "    ratings_df = ratings_df.union(user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_data(user_id, anime_ids):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        user_id: int\n",
    "        anime_ids: list\n",
    "        \n",
    "    return:\n",
    "        inference_df: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    other_anime_ids = anime_df \\\n",
    "        .filter(~col('anime_id').isin(anime_ids)) \\\n",
    "        .select(['anime_id']) \\\n",
    "        .rdd.map(lambda r: r[0]) \\\n",
    "        .collect()\n",
    "    \n",
    "    # create inference rdd\n",
    "    inference_rdd = sc.parallelize(\n",
    "        [(user_id, anime_id) for anime_id in other_anime_ids]\n",
    "    ).map(\n",
    "        lambda x: Row(\n",
    "            user_id=int(x[0]),\n",
    "            anime_id=int(x[1]),\n",
    "        )\n",
    "    )\n",
    "    # transform to inference DF\n",
    "    inference_df = spark.createDataFrame(inference_rdd) \\\n",
    "        .select(['user_id', 'anime_id'])\n",
    "    \n",
    "    return inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference(model,fav_anime,n_recommendations):\n",
    "    # create a userId\n",
    "    user_id = ratings_df.agg({\"userId\": \"max\"}).collect()[0][0] + 1\n",
    "    # get movieIds of favorite movies\n",
    "    anime_ids = regex_matching(fav_anime)\n",
    "    # append new user with his/her ratings into data\n",
    "    append_ratings(user_id, anime_ids)\n",
    "    # matrix factorization\n",
    "    model = model.fit(ratings_df)\n",
    "    # get data for inferencing\n",
    "    inference_df = create_inference_data(user_id, anime_ids)\n",
    "    # make inference\n",
    "    return model.transform(inference_df) \\\n",
    "        .select(['anime_id', 'prediction']) \\\n",
    "        .orderBy('prediction', ascending=False) \\\n",
    "        .rdd.map(lambda r: (r[0], r[1])) \\\n",
    "        .take(n_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ratings = ratings_raw.filter(lambda line: line != header) \\\n",
    "            .map(lambda line: line.split(\",\")) \\\n",
    "            .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_id, name, genre, type, episodes, rating, members = [ '{}'.format(x) for x in list(csv.reader([input_string], delimiter=',', quotechar='\"'))[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ratings_RDD.take(1)[0]\n",
    "        return ratings_RDD \\\n",
    "            .filter(lambda line: line != header) \\\n",
    "            .map(lambda line: line.split(\",\")) \\\n",
    "            .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_anime_data(input_string):\n",
    "    anime_id, name, genre, type, episodes, rating, members = [ '{}'.format(x) for x in list(csv.reader([input_string], delimiter=',', quotechar='\"'))[0] ]\n",
    "    anime_id = int(anime_id)\n",
    "    episodes = int(episodes)\n",
    "    rating = float(rating)\n",
    "    members = int(members)\n",
    "    return [(anime_id, name, type,rating,members, token) for token in genre.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_clean = anime_raw.flatMap(clean_anime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(anime_clean.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_schema = StructType( [\n",
    "    StructField('anime_id',IntegerType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('type',StringType(),True),\n",
    "    StructField('rating',FloatType(),True),\n",
    "    StructField('members',IntegerType(),True),\n",
    "    StructField('genre',StringType(),True) ] )\n",
    "\n",
    "anime = spark.createDataFrame(anime_clean, anime_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot movie genres\n",
    "anime = anime.groupBy(\"anime_id\", \"name\", \"type\",\"rating\",\"members\")\\\n",
    "               .pivot(\"genre\")\\\n",
    "               .agg(F.count(F.col('genre')))\\\n",
    "               .na.fill(0)\n",
    "\n",
    "anime.show(5)\n",
    "anime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
